{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "UAS_NLP (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmr39EP3-3Zp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "067d0ee5-6a9d-450a-e577-b1d72905a836"
      },
      "source": [
        "# !pip install spacy\n",
        "!pip install --upgrade tensorflow==1.15\n",
        "# !python m spacy download en_core_web_lg"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow==1.15 in /usr/local/lib/python3.7/dist-packages (1.15.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.36.2)\n",
            "Requirement already satisfied: gast==0.2.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.2)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.17.3)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.12.1)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.2.0)\n",
            "Requirement already satisfied: tensorboard<1.16.0,>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.0)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (3.3.0)\n",
            "Requirement already satisfied: tensorflow-estimator==1.15.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.15.1)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.2)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.0.8)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.19.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.1.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (0.8.1)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.7/dist-packages (from tensorflow==1.15) (1.34.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.7/dist-packages (from keras-applications>=1.0.8->tensorflow==1.15) (3.1.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (1.0.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (57.2.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.3.4)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (4.6.1)\n",
            "Requirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py->keras-applications>=1.0.8->tensorflow==1.15) (1.5.2)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.5.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard<1.16.0,>=1.15.0->tensorflow==1.15) (3.7.4.3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anuz2WyE--i3"
      },
      "source": [
        "import spacy"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T18a2Ge-_4GG"
      },
      "source": [
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uB722i-pBRNE"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rx7haDIfDHQY"
      },
      "source": [
        "#Insert data to dict\n",
        "\n",
        "df = {\n",
        "    'Data' : ['I feel like I am drowning. #depression #anxiety #failure #worthless',\n",
        "              '#panic Panic attack from fear of starting new medication',\n",
        "              \"My bus was in a car crash... I'm still shaking a bit... This week was an absolute horror and this was the icing on the cake...#terrible\",\n",
        "              'Just got back from seeing @GaryDelaney in Burslem.AMAZING!! Face still hurts from laughing so much #hilarious',\n",
        "              \"It's the #FirstDayofFall and I'm so happy. Sipping my #PumpkinSpice flavoured coffee and #smiling! Happy Fall everyone! #amwriting\",\n",
        "              'Morning all! Of course it is sunny on this Monday morning to cheerfully welcome us back to work.:)'],\n",
        "      \n",
        "    'Label' : ['fear','fear','fear','joy','joy','joy']\n",
        "}"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 234
        },
        "id": "EQJMxaMhDkRK",
        "outputId": "f7951733-d45a-4ee2-864a-d7e558cd48e1"
      },
      "source": [
        "#Dict to dataframe\n",
        "\n",
        "df = pd.DataFrame.from_dict(df)\n",
        "df"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Data</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>I feel like I am drowning. #depression #anxiet...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#panic Panic attack from fear of starting new ...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>My bus was in a car crash... I'm still shaking...</td>\n",
              "      <td>fear</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Just got back from seeing @GaryDelaney in Burs...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>It's the #FirstDayofFall and I'm so happy. Sip...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>Morning all! Of course it is sunny on this Mon...</td>\n",
              "      <td>joy</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                Data Label\n",
              "0  I feel like I am drowning. #depression #anxiet...  fear\n",
              "1  #panic Panic attack from fear of starting new ...  fear\n",
              "2  My bus was in a car crash... I'm still shaking...  fear\n",
              "3  Just got back from seeing @GaryDelaney in Burs...   joy\n",
              "4  It's the #FirstDayofFall and I'm so happy. Sip...   joy\n",
              "5  Morning all! Of course it is sunny on this Mon...   joy"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BW-r0_OITj8M"
      },
      "source": [
        "### **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "22bCvO-qFLDz",
        "outputId": "8b1a92f6-74e4-4437-dcc3-a24dd2cfc646"
      },
      "source": [
        "import re\n",
        "import string\n",
        "#Data preprocessing\n",
        "\n",
        "def get_clean(input_str):\n",
        "  input_str = input_str.lower() #Convert text to lowercase\n",
        "  input_str = re.sub(r'\\d+', '', input_str) #Remove numbers\n",
        "  input_str = input_str.strip() #Remove whitespaces\n",
        "  input_str = re.sub(r'[^\\w\\s]','',input_str) #Remove punctuation\n",
        "  return input_str\n",
        "df['Data'] = df['Data'].apply(lambda x: get_clean(x))\n",
        "df['Data']"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    i feel like i am drowning depression anxiety f...\n",
              "1    panic panic attack from fear of starting new m...\n",
              "2    my bus was in a car crash im still shaking a b...\n",
              "3    just got back from seeing garydelaney in bursl...\n",
              "4    its the firstdayoffall and im so happy sipping...\n",
              "5    morning all of course it is sunny on this mond...\n",
              "Name: Data, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zxvcyD4_6_w1",
        "outputId": "518c34dd-33ba-4e46-b5e5-e029b2ab14de"
      },
      "source": [
        "#Removing stop words\n",
        "#Stop words are the words that are most common used (for example in english is (a,the,am,are, etc.))\n",
        "import nltk\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "stopwords = set(stopwords.words('english'))\n",
        "def clean_stopwords(input_str):\n",
        "  return \" \".join([word for word in str(input_str).split() if word not in stopwords])\n",
        "  \n",
        "df['Data'] = df['Data'].apply(lambda x: clean_stopwords(x))\n",
        "print(df['Data'])"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "0    feel like drowning depression anxiety failure ...\n",
            "1      panic panic attack fear starting new medication\n",
            "2    bus car crash im still shaking bit week absolu...\n",
            "3    got back seeing garydelaney burslemamazing fac...\n",
            "4    firstdayoffall im happy sipping pumpkinspice f...\n",
            "5    morning course sunny monday morning cheerfully...\n",
            "Name: Data, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XMY1h80WWZuT",
        "outputId": "9bd82b41-c25b-47ac-bbbe-b2c3111e35a1"
      },
      "source": [
        "#Word Tokenizing\n",
        "from nltk.tokenize import RegexpTokenizer\n",
        "\n",
        "tokenizer = RegexpTokenizer(r\"\\w+\")\n",
        "df['Data'] = df['Data'].apply(tokenizer.tokenize)\n",
        "print(df['Data'])"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0    [feel, like, drowning, depression, anxiety, fa...\n",
            "1    [panic, panic, attack, fear, starting, new, me...\n",
            "2    [bus, car, crash, im, still, shaking, bit, wee...\n",
            "3    [got, back, seeing, garydelaney, burslemamazin...\n",
            "4    [firstdayoffall, im, happy, sipping, pumpkinsp...\n",
            "5    [morning, course, sunny, monday, morning, chee...\n",
            "Name: Data, dtype: object\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v05WWBrtWIG6",
        "outputId": "26605f69-bf3a-417b-b544-1c59f2e3f4ce"
      },
      "source": [
        "#Word Stemming from nltk library\n",
        "st = nltk.PorterStemmer()\n",
        "def stemming_on_text(data):\n",
        "    text = [st.stem(word) for word in data]\n",
        "    return text\n",
        "    \n",
        "df['Data']= df['Data'].apply(lambda x: stemming_on_text(x))\n",
        "df['Data'].head()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [feel, like, drown, depress, anxieti, failur, ...\n",
              "1      [panic, panic, attack, fear, start, new, medic]\n",
              "2    [bu, car, crash, im, still, shake, bit, week, ...\n",
              "3    [got, back, see, garydelaney, burslemamaz, fac...\n",
              "4    [firstdayoffal, im, happi, sip, pumpkinspic, f...\n",
              "Name: Data, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dJvLnAi32t7t",
        "outputId": "763934c3-9d86-461b-d2d4-ecbc4f84fd99"
      },
      "source": [
        "np.asarray(df['Data'][5]).shape"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m4M5nMhoTQhx"
      },
      "source": [
        "### **Word2Vec**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wKaqmfOcHpsZ",
        "outputId": "99d7d127-9b02-4b9f-e3ec-143c43ea0cf8"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.test.utils import common_texts\n",
        "\n",
        "# model = Word2Vec(sentences=common_texts, vector_size=100, window=5, min_count=1, workers=4)\n",
        "# model.save(\"word2vec.model\")\n",
        "# vector = model.wv['computer']  # get numpy vector of a word\n",
        "\n",
        "model = Word2Vec(sentences = df['Data'], min_count = 1)\n",
        "model.save(\"word2vec.model\")\n",
        "test = model.wv['absolut']\n",
        "test.shape"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIGx-dAHJ-OV",
        "outputId": "7bd58a93-5507-4dc3-a159-358407b30fce"
      },
      "source": [
        "#Display Saved word in model\n",
        "words = list(model.wv.vocab)\n",
        "words"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['feel',\n",
              " 'like',\n",
              " 'drown',\n",
              " 'depress',\n",
              " 'anxieti',\n",
              " 'failur',\n",
              " 'worthless',\n",
              " 'panic',\n",
              " 'attack',\n",
              " 'fear',\n",
              " 'start',\n",
              " 'new',\n",
              " 'medic',\n",
              " 'bu',\n",
              " 'car',\n",
              " 'crash',\n",
              " 'im',\n",
              " 'still',\n",
              " 'shake',\n",
              " 'bit',\n",
              " 'week',\n",
              " 'absolut',\n",
              " 'horror',\n",
              " 'ice',\n",
              " 'caketerr',\n",
              " 'got',\n",
              " 'back',\n",
              " 'see',\n",
              " 'garydelaney',\n",
              " 'burslemamaz',\n",
              " 'face',\n",
              " 'hurt',\n",
              " 'laugh',\n",
              " 'much',\n",
              " 'hilari',\n",
              " 'firstdayoffal',\n",
              " 'happi',\n",
              " 'sip',\n",
              " 'pumpkinspic',\n",
              " 'flavour',\n",
              " 'coffe',\n",
              " 'smile',\n",
              " 'fall',\n",
              " 'everyon',\n",
              " 'amwrit',\n",
              " 'morn',\n",
              " 'cours',\n",
              " 'sunni',\n",
              " 'monday',\n",
              " 'cheer',\n",
              " 'welcom',\n",
              " 'us',\n",
              " 'work']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SDr_SlQmLe1M"
      },
      "source": [
        "def get_vector(word):\n",
        "  vector = model.wv[word]\n",
        "  return vector"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vnnho3PLw0Z",
        "outputId": "ec473492-172a-4fd9-f79b-acb12792ad8b"
      },
      "source": [
        "df['Vec'] = df['Data'].apply(lambda x: get_vector(x))\n",
        "df['Vec'][5].shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fyTDwCegN42e",
        "outputId": "3d359106-d96d-48ef-b072-0df3393fcbcd"
      },
      "source": [
        "data = np.asarray(df['Data'])\n",
        "len(data[5])"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oxElobr2My7q",
        "outputId": "19fb2c8a-74ec-414f-a6cb-4ebbb7db6e01"
      },
      "source": [
        "#Checking shape -> 12 words and every words have 100 vectors \n",
        "\n",
        "vec = np.asarray(df['Vec'])\n",
        "vec[2].shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(12, 100)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGO-rqtlFq5m",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5a69f7f4-8b69-44ec-a437-598eaef94028"
      },
      "source": [
        "#Saving Unique Words\n",
        "\n",
        "data = np.concatenate(data, axis=0)\n",
        "data.shape"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SH-fidczQAvY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e3508ae-dc62-4436-f3b4-1a64346bcd80"
      },
      "source": [
        "unique_data = []\n",
        "for word in data:\n",
        "  if word not in unique_data:\n",
        "    unique_data.append(word)\n",
        "\n",
        "unique_data.sort()\n",
        "len(unique_data)"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zSLC6ikSyzzw",
        "outputId": "411d9528-4bd3-4755-ebe7-8cecd74a2390"
      },
      "source": [
        "#Test\n",
        "\n",
        "print(unique_data[0])\n",
        "print(get_vector('absolut'))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "absolut\n",
            "[ 7.3665427e-04  2.9562765e-03  2.4638257e-03 -3.9702067e-03\n",
            "  4.5946129e-03  1.8884202e-03 -5.9660041e-04 -2.3222216e-03\n",
            "  1.1366222e-03 -1.4209604e-03 -2.8019601e-03 -1.6894558e-03\n",
            " -1.9876771e-03 -2.2878964e-03  1.3562836e-03  2.8597664e-03\n",
            "  2.8208760e-03 -1.1556908e-03 -4.4842493e-03  1.4949493e-03\n",
            "  2.5785873e-03  2.4665825e-04 -1.9986723e-03 -3.4684292e-04\n",
            "  2.6360676e-03 -2.0788135e-03 -1.0706028e-03 -1.2174406e-03\n",
            " -3.2019867e-03 -7.2720030e-04  1.0882072e-03 -1.0610069e-03\n",
            "  7.7589863e-04  3.2234404e-03  8.9568624e-05  2.9428580e-03\n",
            " -4.9179583e-03  1.2663639e-03  4.9468321e-03  4.5471922e-03\n",
            "  2.8727839e-03 -1.0132897e-03  1.3074636e-03 -5.8119098e-04\n",
            "  4.4467677e-03  1.3963005e-03 -1.5611028e-03 -2.9251303e-03\n",
            "  4.3848398e-04 -3.2612714e-03 -1.0903620e-03 -2.0899863e-03\n",
            "  1.4434468e-03  2.6875108e-03  3.7389162e-03  1.5185140e-03\n",
            " -4.2830482e-03 -4.2191902e-03 -4.5163413e-03  2.6211288e-04\n",
            "  1.3018927e-03  4.1641728e-03  1.7365714e-03 -1.3530446e-03\n",
            "  4.2863186e-03 -3.1803900e-03  3.9707297e-03 -1.0932077e-03\n",
            " -6.7923882e-04  1.6070624e-03 -1.4941917e-03  8.8627433e-04\n",
            " -1.3270279e-03 -3.8845199e-03 -4.5375875e-04 -4.5311050e-03\n",
            " -3.4191967e-03 -2.4446037e-03 -2.3953710e-03  9.6126448e-04\n",
            "  1.0595288e-03  7.5781718e-04 -3.5403071e-03  9.5086452e-04\n",
            " -3.9150375e-03 -1.9289147e-03 -7.6591416e-04 -4.7887391e-03\n",
            "  4.6465825e-03 -3.1803024e-03  4.1265446e-03  3.8324129e-03\n",
            " -3.2445003e-04 -1.9500843e-03  3.0916671e-03  7.0585002e-04\n",
            "  3.9163316e-03 -4.9720018e-04  3.7828374e-03  1.0177252e-03]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c9t67JnAQ_di",
        "outputId": "9ba7cdee-b195-44f0-8c7f-3d9b4ed71550"
      },
      "source": [
        "#Length of unique words\n",
        "\n",
        "np.asarray(unique_data).shape"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(53,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fonXPSul3dQj"
      },
      "source": [
        "### **Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhZ5-RuNAPex",
        "outputId": "897f82f5-95a8-4924-bfd4-90d9f9dd990e"
      },
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "\n",
        "#Convert vector into matrix\n",
        "seq = Tokenizer(nb_words = 500, split='')\n",
        "seq.fit_on_texts(df['Data'])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras_preprocessing/text.py:180: UserWarning: The `nb_words` argument in `Tokenizer` has been renamed `num_words`.\n",
            "  warnings.warn('The `nb_words` argument in `Tokenizer` '\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UdiAnRzZASDa",
        "outputId": "b4b52b8b-a99c-4e0e-f6cd-d6d2d1ae30dd"
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "sequence = seq.texts_to_sequences(df['Data'])\n",
        "sequence = pad_sequences(sequence, maxlen=12, padding='post', truncating='post')\n",
        "print(sequence)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 7  8  9 10 11 12 13  0  0  0  0  0]\n",
            " [ 1  1 14 15 16 17 18  0  0  0  0  0]\n",
            " [19 20 21  2  3 22 23 24 25 26 27 28]\n",
            " [29  4 30 31 32 33  3 34 35 36 37  0]\n",
            " [38  2  5 39 40 41 42 43  5 44 45 46]\n",
            " [ 6 47 48 49  6 50 51 52  4 53  0  0]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HZY62LW51TfE",
        "outputId": "d4f4a874-d819-4580-bd5a-4d37cab1b764"
      },
      "source": [
        "#words must be changed to a list to fit the matrix\n",
        "matrix = np.zeros((53,100))\n",
        "\n",
        "for i in range (len(words)) :\n",
        "    matrix[i] = model[words[i]]"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \"\"\"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aTB4etQvV0F0",
        "outputId": "e35946dd-d92e-4fb6-d55f-921b0b51aad3"
      },
      "source": [
        "matrix[0]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-1.4260252e-03, -3.3456672e-03,  2.1479698e-03, -3.8539576e-03,\n",
              "        3.6561023e-03, -2.4044935e-03,  2.7421091e-03,  1.5145054e-03,\n",
              "        4.8989281e-03,  2.3729953e-03, -3.4177792e-03,  2.3020108e-03,\n",
              "       -2.2908410e-03, -5.0000451e-04,  8.3262438e-04,  1.7055906e-03,\n",
              "        3.4298578e-03, -6.1959022e-04,  2.3239164e-03,  3.1632229e-03,\n",
              "       -2.4807705e-03, -5.7033938e-04,  4.0350705e-03, -2.0759259e-03,\n",
              "        4.3828185e-03, -1.3512889e-03, -3.4341309e-03, -2.7345696e-03,\n",
              "       -6.7239854e-04, -1.2932652e-04,  2.6036014e-03, -4.7495943e-03,\n",
              "        3.9427471e-03, -1.0017054e-03, -8.6219603e-04,  1.5032404e-03,\n",
              "        2.3588231e-03, -1.4815860e-03, -2.0398106e-03,  2.4969450e-03,\n",
              "        4.7780033e-03, -3.8032359e-04,  2.1443160e-03,  3.1246110e-03,\n",
              "       -1.9796146e-03, -3.6620526e-03, -3.7659300e-03, -2.5886218e-03,\n",
              "        3.6550788e-03,  4.4156364e-04, -1.8596480e-03, -2.6805573e-03,\n",
              "       -2.3094506e-03, -1.9999323e-04,  1.9131053e-03, -2.4462012e-03,\n",
              "        4.6562176e-04, -1.7771014e-03, -2.2214386e-03,  6.9508527e-04,\n",
              "       -3.1604001e-03, -7.4205472e-04, -5.7736895e-04, -8.3058898e-04,\n",
              "       -2.9812602e-04, -4.4613574e-03, -2.9760723e-03,  1.0633278e-03,\n",
              "        4.7995052e-03,  2.5677218e-03, -3.3558563e-03, -3.6480525e-04,\n",
              "        4.8312312e-03,  1.4788918e-03,  2.8506021e-03, -4.5605372e-03,\n",
              "       -1.2374109e-03,  9.4468484e-04,  3.1560382e-03,  1.0578992e-03,\n",
              "        1.6004846e-03,  8.2870567e-04,  4.2168886e-04,  4.7286772e-03,\n",
              "        3.2336412e-03,  4.2247213e-03, -3.3459582e-03, -4.1211545e-04,\n",
              "       -8.9618494e-04,  4.1033332e-03,  6.8879669e-04, -4.5636059e-03,\n",
              "       -2.6225750e-03, -3.2805973e-03, -4.2138202e-03, -1.1081331e-03,\n",
              "       -7.7478380e-06, -1.6906162e-03, -4.7144461e-03,  1.6809027e-03],\n",
              "      dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BWzMT1Y03bdx",
        "outputId": "27e166ad-36e8-48ef-b181-d7dffd515b6c"
      },
      "source": [
        "y = df['Label']\n",
        "y = y.values.reshape(-1,1)\n",
        "y"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([['fear'],\n",
              "       ['fear'],\n",
              "       ['fear'],\n",
              "       ['joy'],\n",
              "       ['joy'],\n",
              "       ['joy']], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jYHIUCERDz3v",
        "outputId": "cd74072f-f7eb-4106-9e77-1ef42814eac7"
      },
      "source": [
        "X = sequence\n",
        "X"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 7,  8,  9, 10, 11, 12, 13,  0,  0,  0,  0,  0],\n",
              "       [ 1,  1, 14, 15, 16, 17, 18,  0,  0,  0,  0,  0],\n",
              "       [19, 20, 21,  2,  3, 22, 23, 24, 25, 26, 27, 28],\n",
              "       [29,  4, 30, 31, 32, 33,  3, 34, 35, 36, 37,  0],\n",
              "       [38,  2,  5, 39, 40, 41, 42, 43,  5, 44, 45, 46],\n",
              "       [ 6, 47, 48, 49,  6, 50, 51, 52,  4, 53,  0,  0]], dtype=int32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tieLzUlN3jAH",
        "outputId": "bce2f3c9-fead-46f6-9a71-2da624a72934"
      },
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#Normalization -> x_data already normalized, we must change label from string to int so that the program can read it\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(X)\n",
        "encoder = OneHotEncoder()\n",
        "y = encoder.fit_transform(y.reshape(-1,1)).toarray()\n",
        "print(y.shape)\n",
        "print(X.shape)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(6, 2)\n",
            "(6, 12)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_RMeMT9jEKS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d8592403-2d16-45a6-cc32-7b6b1a458396"
      },
      "source": [
        "X"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-0.72545355, -0.34993946, -0.83996873, -0.86189827, -0.51651492,\n",
              "        -1.27785269, -0.72450595, -1.27940554, -0.85029809, -1.29732176,\n",
              "        -0.96129498, -0.67767386],\n",
              "       [-1.17573506, -0.78221762, -0.4947761 , -0.56123608, -0.14757569,\n",
              "        -0.90566259, -0.42262847, -1.27940554, -0.85029809, -1.29732176,\n",
              "        -0.96129498, -0.67767386],\n",
              "       [ 0.17510948,  0.39110881, -0.01150642, -1.34295776, -1.10681768,\n",
              "        -0.53347248, -0.12075099, -0.07525915,  0.99817601, -0.02447777,\n",
              "         0.46741866,  0.86082896],\n",
              "       [ 0.92557867, -0.59695555,  0.60984031,  0.40088291,  1.03302983,\n",
              "         0.28534575, -1.32826091,  0.42646851,  1.73756565,  0.46507761,\n",
              "         0.99657186, -0.67767386],\n",
              "       [ 1.60100094, -0.7204636 , -1.11612283,  0.88194241,  1.62333259,\n",
              "         0.88084991,  1.02638343,  0.87802341, -0.48060327,  0.85672191,\n",
              "         1.41989443,  1.84986649],\n",
              "       [-0.80050047,  2.05846742,  1.85253377,  1.48326678, -0.88545414,\n",
              "         1.5507921 ,  1.56976289,  1.32957831, -0.55454223,  1.29732176,\n",
              "        -0.96129498, -0.67767386]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKmSJrXroW7Q"
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "#Split data into data training and testing\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state=2)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zbcbRdTfohEM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52673d6d-d201-4dce-d088-b381433f0d26"
      },
      "source": [
        "x_train.shape, y_train.shape"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4, 12), (4, 2))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gi-8dAnxUOFS"
      },
      "source": [
        "matrix = np.float32(matrix)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X9kCsMLApmmX"
      },
      "source": [
        "import tensorflow as tf\n",
        "#initialize variable (Weight, Bias)\n",
        "layer = {\n",
        "    'input' : 12,\n",
        "    'hidden' : 53,\n",
        "    'output' : 2,\n",
        "    'embed' : 100\n",
        "}\n",
        "\n",
        "weight = {\n",
        "    # th = to hidden, to = to output\n",
        "    'th' : tf.Variable(tf.random_normal([layer['input'], layer['hidden']])),\n",
        "    'to' : tf.Variable(tf.random_normal([layer['embed'], layer['output']])),\n",
        "    'em' : tf.Variable(matrix)\n",
        "}\n",
        "\n",
        "bias = {\n",
        "    'th' : tf.Variable(tf.random_normal([layer['hidden']])),\n",
        "    'to' : tf.Variable(tf.random_normal([layer['output']])),\n",
        "    'hth': tf.Variable(tf.random_normal([layer['embed']]))\n",
        "}"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0HcjzihGqE9c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d4b2209c-5685-456e-9800-ccd5d7098ee9"
      },
      "source": [
        "x = tf.placeholder(tf.float32, [None, layer['input']])\n",
        "target = tf.placeholder(tf.float32, [None, layer['output']])\n",
        "\n",
        "print(x)\n",
        "print(target)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tensor(\"Placeholder:0\", shape=(?, 12), dtype=float32)\n",
            "Tensor(\"Placeholder_1:0\", shape=(?, 2), dtype=float32)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oSvmgnvsqzXE"
      },
      "source": [
        "#function forward pass\n",
        "def forward_pass():\n",
        "    wx_b1 = tf.matmul(x, weight['th']) + bias['th']\n",
        "    y1 = tf.nn.sigmoid(wx_b1)\n",
        "\n",
        "    wx_b2 = tf.matmul(y1, weight['em']) + bias['hth']\n",
        "    y2 = tf.nn.sigmoid(wx_b2)\n",
        "\n",
        "    wx_b3 = tf.matmul(y2, weight['to']) + bias['to']\n",
        "    y3 = tf.nn.sigmoid(wx_b3)\n",
        "\n",
        "    return y3"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4UQ7LByTXmW"
      },
      "source": [
        "# isi value prediction\n",
        "y = forward_pass()"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSMlwQfoq1S3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d9b0e3c-c3da-4f27-b84e-7265afc3a7ac"
      },
      "source": [
        "# variable pembantu dalam training dan testing\n",
        "epoch = 500\n",
        "alpha = 0.1\n",
        "\n",
        "# MSE\n",
        "error = tf.reduce_mean(0.5 * (target - y)**2)\n",
        "optimizer = tf.train.GradientDescentOptimizer(alpha)\n",
        "train = optimizer.minimize(error)"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.7/dist-packages/tensorflow_core/python/ops/math_grad.py:1375: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yITCA2kdq2-H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f59a5c47-3e9f-4b38-8597-1eff071d9a41"
      },
      "source": [
        "with tf.Session() as sess:\n",
        "  sess.run(tf.global_variables_initializer())\n",
        "  best_error = float('inf')\n",
        "  for i in range(epoch+1):\n",
        "    sess.run(\n",
        "        train,\n",
        "        feed_dict = {\n",
        "            x: x_train,\n",
        "            target: y_train\n",
        "        }\n",
        "    )\n",
        "\n",
        "    if i % 25 == 0:\n",
        "      current_error = sess.run(\n",
        "          error,\n",
        "          feed_dict = {\n",
        "              x: x_train,\n",
        "              target: y_train\n",
        "          }\n",
        "      )\n",
        "      print(f'EPOCH : {i} | ERROR : {current_error} |')\n",
        "\n",
        "  true_prediction = tf.equal(tf.argmax(y, axis = 1), tf.argmax(target, axis = 1))\n",
        "  accuracy = tf.reduce_mean(tf.cast(true_prediction, tf.float32))\n",
        "  accuracy = sess.run(\n",
        "      accuracy,\n",
        "      feed_dict = {\n",
        "          x: x_test,\n",
        "          target: y_test\n",
        "      }\n",
        "  )\n",
        "  evaluation = y.eval(feed_dict = {\n",
        "      x: x_test\n",
        "  })  \n",
        "  print(f'ACCURACY: {accuracy:}')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH : 0 | ERROR : 0.12677158415317535 |\n",
            "EPOCH : 25 | ERROR : 0.04720999300479889 |\n",
            "EPOCH : 50 | ERROR : 0.0251912958920002 |\n",
            "EPOCH : 75 | ERROR : 0.01611074060201645 |\n",
            "EPOCH : 100 | ERROR : 0.01146466564387083 |\n",
            "EPOCH : 125 | ERROR : 0.00873558409512043 |\n",
            "EPOCH : 150 | ERROR : 0.006974741816520691 |\n",
            "EPOCH : 175 | ERROR : 0.005759688559919596 |\n",
            "EPOCH : 200 | ERROR : 0.004878186620771885 |\n",
            "EPOCH : 225 | ERROR : 0.004213489126414061 |\n",
            "EPOCH : 250 | ERROR : 0.0036966949701309204 |\n",
            "EPOCH : 275 | ERROR : 0.003284806152805686 |\n",
            "EPOCH : 300 | ERROR : 0.00294973561540246 |\n",
            "EPOCH : 325 | ERROR : 0.0026724322233349085 |\n",
            "EPOCH : 350 | ERROR : 0.0024395582731813192 |\n",
            "EPOCH : 375 | ERROR : 0.0022415267303586006 |\n",
            "EPOCH : 400 | ERROR : 0.0020712758414447308 |\n",
            "EPOCH : 425 | ERROR : 0.0019235007930547 |\n",
            "EPOCH : 450 | ERROR : 0.0017941489350050688 |\n",
            "EPOCH : 475 | ERROR : 0.0016800636658445 |\n",
            "EPOCH : 500 | ERROR : 0.0015787668526172638 |\n",
            "ACCURACY: 1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R22q2H25vC05"
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, evaluation, target_names=target_names))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}